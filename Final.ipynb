{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Adway\\Desktop\\Mini Project\\Data File\\MAX data\"\n",
    "dataset1 = pd.read_csv(r\"C:\\Users\\Adway\\Desktop\\Mini Project\\Data File\\New Cleaned\\Mini Project\\S0021\\SS0028.csv\",) \n",
    "plt.title(\"Raw PPG Signal\") \n",
    "dataset1 = dataset1.rename(columns = {'S2': 'PLETH'})\n",
    "#dataset1 = dataset1[9000:len(dataset1)-1]                   Use if directly taking with MARKERS in the signal\n",
    "#dataset1 = dataset1.reset_index(drop = True)\n",
    "#drop_locs = dataset1.loc[dataset1['PLETH'] == 2147483647].index\n",
    "#dataset1 = dataset1.drop(drop_locs)\n",
    "dataset = dataset1.PLETH\n",
    "plt.plot(dataset) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.signal import butter, filtfilt, welch, periodogram, resample_poly, resample, firwin\n",
    "\n",
    "def highpass(data,f):\n",
    "    '''Defines standard Butterworth lowpass filter.\n",
    "    '''\n",
    "    numtaps = 77\n",
    "    filterc = firwin(numtaps, f)\n",
    "    filtered =  np.array([np_convolve(xi, filterc , mode='valid') for xi in x])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "measures = {}\n",
    "def get_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    dataset1 = data.rename(columns = {'S2': 'PLETH'})\n",
    "    dataset = dataset1.PLETH\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(dataset):\n",
    "    \n",
    "    range = np.max(dataset) - np.min(dataset)\n",
    "    minimum = np.min(dataset)\n",
    "    dataset = 1024 * ((dataset - minimum) / range)\n",
    "    plt.plot(dataset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_peaks(dataset, iterations=2):\n",
    "    \n",
    "    scale_data(dataset)\n",
    "    for i in range(iterations):\n",
    "        dataset = np.power(dataset, 2)\n",
    "        dataset = scale_data(dataset)\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingavg(dataset, hrw, fs):\n",
    "    mov_avg = dataset['PLETH'].rolling(int(hrw*fs)).mean()\n",
    "    avg_hr = (np.mean(dataset.PLETH))\n",
    "    mov_avg = [avg_hr if math.isnan(x) else x for x in mov_avg]\n",
    "    #mov_avg = [x*1.15 for x in mov_avg]\n",
    "    dataset['new_rollingmean'] = mov_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(dataset):\n",
    "    w = []\n",
    "    peaklist = []\n",
    "    listpos = 0\n",
    "    for datapoint in dataset.PLETH:\n",
    "        rollingmean = dataset.new_rollingmean[listpos]\n",
    "        if (datapoint <= rollingmean) and (len(w) <= 1):\n",
    "            listpos += 1\n",
    "        elif (datapoint > rollingmean):\n",
    "            w.append(datapoint)\n",
    "            listpos += 1\n",
    "        else:\n",
    "            maximum = max(w)\n",
    "            beatposition = listpos - len(w) + (w.index(max(w)))\n",
    "            peaklist.append(beatposition)\n",
    "            w = []\n",
    "            listpos += 1\n",
    "    measures['peaklist'] = peaklist\n",
    "    measures['ybeat'] = [dataset.PLETH[x] for x in peaklist]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_RR(dataset, fs):\n",
    "#     RR_list = []\n",
    "#     peaklist = measures['peaklist']\n",
    "#     cnt = 0\n",
    "#     while (cnt < (len(peaklist)-1)):\n",
    "#         RR_interval = (peaklist[cnt+1] - peaklist[cnt])\n",
    "#         ms_dist = ((RR_interval / fs) * 1000.0)\n",
    "#         RR_list.append(ms_dist)\n",
    "#         cnt += 1\n",
    "    \n",
    "#     RR_dif = []\n",
    "#     RR_sqdif = []\n",
    "#     cnt = 0\n",
    "#     while (cnt < (len(RR_list)-1)):\n",
    "#         RR_dif.append(abs(RR_list[cnt] - RR_list[cnt+1]))\n",
    "#         RR_sqdif.append(math.pow(RR_dif[cnt] - RR_list[cnt+1], 2))\n",
    "#         cnt += 1\n",
    "#     measures['RR_list'] = RR_list\n",
    "#     measures['Rdif'] = RR_dif\n",
    "#     measures['Rsqdif'] = RR_sqdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_RR(peaklist, sample_rate, working_data={}):\n",
    "    \n",
    "    #peaklist = np.array(peaklist) #cast numpy array to be sure or correct array type\n",
    "\n",
    "    #delete first peak if within first 150ms (signal might start mid-beat after peak)\n",
    "    if len(peaklist) > 0:\n",
    "        if peaklist[0] <= ((sample_rate / 1000.0) * 100):\n",
    "            peaklist = np.delete(peaklist, 0)\n",
    "            working_data['peaklist'] = peaklist\n",
    "            working_data['ybeat'] = np.delete(working_data['ybeat'], 0)\n",
    "\n",
    "    rr_list = (np.diff(peaklist) / sample_rate) * 1000.0\n",
    "    rr_diff = np.abs(np.diff(rr_list))\n",
    "    rr_sqdiff = np.power(rr_diff, 2)\n",
    "    working_data['RR_list'] = rr_list\n",
    "    working_data['Rdif'] = rr_diff\n",
    "    working_data['Rsqdif'] = rr_sqdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks_new(dataset,ma_per,fs):\n",
    "    rolmean = [(x+((x/100)*ma_per)) for x in dataset.new_rollingmean]\n",
    "    w = []\n",
    "    peaklist = []\n",
    "    listpos = 0\n",
    "    for datapoint in dataset.PLETH:\n",
    "        rollingmean = dataset.new_rollingmean[listpos]\n",
    "        if (datapoint <= rollingmean) and (len(w) <= 1):\n",
    "            listpos += 1\n",
    "        elif (datapoint > rollingmean):\n",
    "            w.append(datapoint)\n",
    "            listpos += 1\n",
    "        else:\n",
    "            maximum = max(w)\n",
    "            beatposition = listpos - len(w) + (w.index(max(w)))\n",
    "            peaklist.append(beatposition)\n",
    "            w = []\n",
    "            listpos += 1\n",
    "    measures['peaklist'] = peaklist\n",
    "    measures['ybeat'] = [dataset.PLETH[x] for x in peaklist]\n",
    "    measures['rolmean'] = rolmean\n",
    "    calc_RR(peaklist, fs, measures)\n",
    "    measures['rrsd'] = np.std(measures['RR_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_peaks(dataset, fs):\n",
    "    ma_perc_list = [5, 10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 150, 200, 300] #List with moving average raise percentages, make as detailed as you like but keep an eye on speed\n",
    "    rrsd = []\n",
    "    valid_ma = []\n",
    "    for x in ma_perc_list: #Detect peaks with all percentages, append results to list 'rrsd'\n",
    "        detect_peaks_new(dataset, x, fs)\n",
    "        bpm = ((len(measures['peaklist'])/(len(dataset.PLETH)/fs))*60)\n",
    "        measures['bpm_2'] = bpm\n",
    "        rrsd.append([measures['rrsd'], bpm, x])\n",
    "    for x,y,z in rrsd: #Test list entries and select valid measures\n",
    "        if ((x > 1) and ((y > 30) and (y < 130))):\n",
    "            valid_ma.append([x, z])\n",
    "    #measures['best'] = min(valid_ma, key = lambda t: t[0])[1] #Save the ma_perc for plotting purposes later on (not needed)\n",
    "#     detect_peaks(dataset, min(valid_ma, key = lambda t: t[0])[1], fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_peaks():\n",
    "    \n",
    "    RR_list = measures['RR_list'] #Get measures\n",
    "    peaklist = measures['peaklist']\n",
    "    ybeat = measures['ybeat']\n",
    "    upper_threshold = (np.mean(RR_list) + 180) #Set thresholds\n",
    "    lower_threshold = (np.mean(RR_list) - 40)\n",
    "    #detect outliers\n",
    "    cnt = 0\n",
    "    removed_beats = []\n",
    "    removed_beats_y = []\n",
    "    RR2 = []\n",
    "    while cnt < len(RR_list):\n",
    "        if (RR_list[cnt] < upper_threshold) and (RR_list[cnt] > lower_threshold):\n",
    "            RR2.append(RR_list[cnt])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            removed_beats.append(peaklist[cnt])\n",
    "            removed_beats_y.append(ybeat[cnt])\n",
    "            cnt += 1\n",
    "            \n",
    "    measures['RR_list_new'] = RR2\n",
    "    measures['removed_peaks'] = removed_beats\n",
    "    #newpeak = list(set(peaklist)-set(removed_beats))\n",
    "    newpeak = [i for i in peaklist + removed_beats if i not in peaklist or i not in removed_beats]\n",
    "    #newpeak1 = newpeak.sort()\n",
    "    measures['new_peaklist'] = newpeak\n",
    "    #newpeak_y = list(set(ybeat)-set(removed_beats_y))\n",
    "    #newpeak_y1 = newpeak_y.sort()\n",
    "    newpeak_y = [i for i in ybeat + removed_beats_y if i not in ybeat or i not in removed_beats_y]\n",
    "    measures['newpeaks_y'] = newpeak_y\n",
    "    plt.subplot(211)\n",
    "    plt.title('Marked Uncertain Peaks')\n",
    "    plt.plot(dataset1.PLETH, color='blue', alpha=0.6, label='heart rate signal')\n",
    "    plt.plot(measures['rolmean'], color='green')\n",
    "    plt.scatter(measures['peaklist'], measures['ybeat'], color='green')\n",
    "    plt.scatter(removed_beats, removed_beats_y, color='red', label='Detection uncertain')\n",
    "    plt.legend(framealpha=0.6, loc=4)\n",
    "    plt.subplot(212)\n",
    "    plt.title(\"RR-intervals with thresholds\")\n",
    "    plt.plot(RR_list)\n",
    "    plt.axhline(y=upper_threshold, color='red')\n",
    "    plt.axhline(y=lower_threshold, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bpm(dataset):\n",
    "    RR_list1 = measures['RR_list']\n",
    "    measures['bpm'] = 60000 / np.mean(RR_list1)\n",
    "    #measures['bpm'] = (100/np.mean(RR_list_new))*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(dataset, title):\n",
    "    peaklist = measures['new_peaklist']\n",
    "    ybeat = measures['newpeaks_y']\n",
    "    \n",
    "#     l1 = len( measures['new_peaklist'])\n",
    "#     l2 = len(measures['newpeaks_y'])\n",
    "#     if l2 < l1:\n",
    "#         peaklist = measures['new_peaklist'][0:l2]\n",
    "    \n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(dataset.PLETH, alpha=0.5, color='blue', label=\"raw signal\")\n",
    "    plt.plot(dataset.new_rollingmean, color ='green', label=\"moving average\")\n",
    "    plt.scatter(peaklist, ybeat, color='red', label=\"average: %.1f BPM\" %measures['bpm'])\n",
    "    plt.legend(loc=4, framealpha=0.6)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measures():\n",
    "    RR_list = measures['RR_list']\n",
    "    RR_diff = measures['Rdif']\n",
    "    RR_sqdiff = measures['Rsqdif']\n",
    "    measures['bpm'] = 60000 / np.mean(RR_list)\n",
    "    measures['ibi'] = np.mean(RR_list)\n",
    "    measures['sdnn'] = np.std(RR_list)\n",
    "    measures['sdsd'] = np.std(RR_diff)\n",
    "    measures['rmssd'] = np.sqrt(np.mean(RR_sqdiff))\n",
    "    NN20 = [x for x in RR_diff if (x>20)]\n",
    "    NN50 = [x for x in RR_diff if (x>50)]\n",
    "    measures['nn20'] = NN20\n",
    "    measures['nn50'] = NN50\n",
    "    measures['pnn20'] = float(len(NN20)) / float(len(RR_diff))\n",
    "    measures['pnn50'] = float(len(NN50)) / float(len(RR_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataset, hrw, fs): \n",
    "    \n",
    "    #enhance_peaks(dataset)\n",
    "    movingavg(dataset, hrw, fs)\n",
    "    detect_peaks(dataset)\n",
    "    detect_peaks_new(dataset,30,fs)\n",
    "    fit_peaks(dataset,fs)\n",
    "    better_peaks()\n",
    "    scale_data(dataset)\n",
    "    calc_RR(measures['new_peaklist'], fs, working_data = measures)\n",
    "    calc_bpm(dataset)\n",
    "    time_measures()\n",
    "    plotter(dataset, \"Your PPG Plot  with peaks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "process(dataset1,0.75,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d #Import the interpolate function from SciPy\n",
    "peaklist = measures['new_peaklist'] \n",
    "RR_list = measures['RR_list']\n",
    "RR_x = peaklist[1:] \n",
    "RR_y = RR_list \n",
    "RR_x_new = np.linspace(RR_x[0],RR_x[-1],RR_x[-1]) #Create evenly spaced timeline starting at the second peak, its endpoint and length equal to position of last peak\n",
    "f = interp1d(RR_x, RR_y, kind='cubic') #Interpolate the signal with cubic spline interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Original and Interpolated Signal\")\n",
    "plt.plot(RR_x, RR_y, label=\"Original\", color='blue')\n",
    "plt.plot(RR_x_new, f(RR_x_new), label=\"Interpolated\", color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables\n",
    "fs = 100\n",
    "n = len(dataset1.PLETH) #Length of the signal\n",
    "frq = np.fft.fftfreq(len(dataset1.PLETH), d=((1/fs))) #divide the bins into frequency categories\n",
    "frq = frq[range(n//2)] \n",
    "#Do FFT\n",
    "Y = np.fft.fft(f(RR_x_new))/n #Calculate FFT\n",
    "Y = Y[range(n//2)] #Return one side of the FFT\n",
    "#Plot\n",
    "plt.title(\"Frequency Spectrum of HRV parameter\")\n",
    "plt.xlim(0,0.6) #Limit X axis to frequencies of interest (0-0.6Hz for visibility, we are interested in 0.04-0.5)\n",
    "plt.ylim(0, 50) #Limit Y axis for visibility\n",
    "plt.plot(frq, abs(Y)) #Plot it\n",
    "plt.xlabel(\"Frequencies in Hz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = np.trapz(abs(Y[(frq>=0.04) & (frq<=0.15)])) #Slice frequency spectrum where x is between 0.04 and 0.15Hz (LF), and use NumPy's trapezoidal integration function to find the area\n",
    "print(\"LF:\", lf)\n",
    "hf = np.trapz(abs(Y[(frq>=0.16) & (frq<=0.5)])) #Do the same for 0.16-0.5Hz (HF)\n",
    "print(\"HF:\", hf)\n",
    "\n",
    "measures['LF'] = lf\n",
    "measures['HF'] = hf\n",
    "measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
